# 高并发原则
其实在聊我们的高并发，我一直存在一个疑问到底多少才算高，面试管反反复复提及到的高并发，到底是想问我们什么样的问题，我认为心中有图面试不慌。

## 目录
- [原理](##原理)


### 本质
高并发系统本质就是一个满足多请求、高性能、高可用的一个分布式系统。高并发的高其实就是指的并发读以及并发写的并发容量要高。在我看来要满足这样一个系统需要做到到底是哪些内容
- 请求数一定要少
- 请求量一定要少
- 访问路径一定要短

### 请求数量要少
请求数量要少，其实我认为没有请求就是最快的请求，如果一个时间同步接口，其实最快的方式就是用客户端的本地时针，那么不会存在https 请求，不会存在任何网络开销、服务器处理等等等等的相关环节，所以就想武林高手一样没有招式的武功才是极致武功。

现实过程中这样是不可能的，但是我们得尽可能得利用这样的方案减少请求数量。比如：css.js等文件下发，我们可以通过一个单独的接口访问动态的下发一连串文件

### 请求量一定要少
在我做过的一个项目中让我记忆尤新的是一个接口，大小接近一个MB，而且这个接口是一个首页接口，当时是数据类型APP的一个首页接口。接近一个MB大小的返回量的接口，想一下是多么恐怖，我们当时带宽是使用的是华为云主机包带宽的模式，一分钟烧掉几个G的流量。

接口痛点： 冷热数据未分离，所有数据都是后端组装后端返回。当时接口是满足我们的海外app的即时比分，所有数据都是后台查询中间件、缓存等地方进行拼接返回。其中io读写是很吃CPU，几千人在线的时候直接cpu给涨到300%。

优化方案：冷热数据分离，我们接口是即使比赛接口，之前的返回是近40个字段的返回，而且是一个列表形式的，每次返回需要返回上千条即使比赛信息。实际上球队、联赛、球员等信息是在一天时间内几乎不会变动的，我们将这个信息打包成静态内容写到oss上由cdn做转发缓存，我们主站只需要返回关键内容。


### 一定不要做单点
做单点实际上是不负责任的表现，在实际的应用过程不论是rpc还是api都是要必须支持多开的，rpc可以通过配置中心进行配置，api则由nginx做反向代理完成多点部署。


