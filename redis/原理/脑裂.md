# 脑裂
脑裂：从字面意思上大家大概也知道是什么东西了，就是一个集群中出现多个大脑也就是多个主节点。脑裂只是一种现象
比如，集群中出现两个或者多个节点，客户端不知道写入新的master 还是旧的的master ，如果存在新旧共存就是脑裂。

##目录
 - [脑裂产生的原因](###脑裂产生的原因)
 - [脑裂会导致什么样的问题](###脑裂会导致什么样的问题)
 - [如何预防脑裂](###如何预防脑裂)
 
 #### 脑裂产生的原因什么
 脑裂产生的原因是存在很多的，比如：新主节点上位，原主节点降级成为slave ，因为需要通过哨兵发送slaveof 某个节点
 但此时原主节点因为网络原因没有处理到这个消息，那么名义上它还是一个主节点。
 其实从上面的基础意思上来看的话脑裂就是多个主节点，我们知道主节点产生途径是通过slave 来进行投票选举创建出来的
 那么我们再回顾一下投票的两个阶段：
 - 第一阶段：投票来确认是否让主节点下课。这个节点是：一半以上的节点只要赞成我们主节点下课，那么就会真的把我们redis的
 主节点下课。但是需要注意的是主节点此时只是被标记为：客观下课，真的下课了吗。
 - 第二阶段：选leader ，选完leader来进行主从切换。选leader 需要满足两个条件： 1.投票大于一半以上，2投票大于quorum这个
 设置的数量，之前在哨兵那里有讲的哟。
 
 这两个阶段我们回顾了一下，可能发生的原因是在哪个阶段呢，其实就是在第二个阶段，因为第一个阶段都还没能投票下线主库，主库此时只是
 正在被投票，不代表不能运行了，这里的可能性很多，我就不列举了，后面有空的话我再列举一下。如果在第二个阶段： 
 
 - 原主节点不能处理sentinel请求了
 - sentinel 开始下线投票
 - sentinel 一致认为主节点应该被下线，但是此时主节点恢复了，sentinel在进行第二阶段
 - 原主节点被client写入数据
 - 主从开始切换节点，数据写入新的节点。 原主节点降级成为slave ，清空本地RDB 载入新的主节点的RDB
 
 #### 脑裂会导致什么样的问题
 明显的问题就是脑裂会导致数据丢失，比如说，我原主节点还在写入，新节点没有被写入，然后通知客户端，写入
 新主节点，原主节点降级。那么明显中间过程就会导致数据丢失。
 
 
 #### 如何预防脑裂问题
 现在脑裂问题出现了，根源就是在主节点被确认客观下线后还在写入请求。那么如何解决这个问题呢。
 -  min-slaves-to-write 表示连接到主节点的最小slave数量 
 - min-slaves-max-lag  表示连接到主节点的最大延时
 
那么配置好了过后就是： 至少要求min-slaves-to-write 节点，且数据同步的延时不能超过min-slaves-to-lag
,不然的话master 就会拒绝请求。其实原理还是比较简单。
 
